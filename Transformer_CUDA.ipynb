{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "sc4gxOF5TVJP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from kernel_lib import *\n",
        "from matrix import Matrix\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = [\"This\", \"is\", \"a\", \"sentence\"]\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "pos_enc_sequence_len = 10\n",
        "token_dims = vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.          1.          0.          1.        ]\n",
            " [ 0.841471    0.5403023   0.00999983  0.99995   ]\n",
            " [ 0.90929747 -0.4161468   0.01999867  0.9998    ]\n",
            " [ 0.14112    -0.9899925   0.0299955   0.99955004]\n",
            " [-0.7568025  -0.65364367  0.03998933  0.9992001 ]\n",
            " [-0.9589243   0.28366217  0.04997917  0.99875027]\n",
            " [-0.2794155   0.96017027  0.059964    0.99820054]\n",
            " [ 0.6569866   0.75390226  0.06994285  0.997551  ]\n",
            " [ 0.98935825 -0.14550003  0.07991469  0.99680173]\n",
            " [ 0.4121185  -0.91113025  0.08987855  0.9959527 ]]\n"
          ]
        }
      ],
      "source": [
        "pos_encodings = Matrix(pos_enc_sequence_len, token_dims, np.float32, gpu=True)\n",
        "pos_encodings.alloc_on_gpu()\n",
        "gen_pos_encodings(pos_encodings.a_gpu,\n",
        "                  np.int32(pos_encodings.num_rows),\n",
        "                  np.int32(pos_encodings.num_cols),\n",
        "                  block=(pos_encodings.num_cols, pos_encodings.num_rows, 1))\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(pos_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "They are similar!\n"
          ]
        }
      ],
      "source": [
        "rows_np = np.arange(pos_enc_sequence_len)\n",
        "rows_np = rows_np[:, np.newaxis]\n",
        "\n",
        "pos_cols_np = np.arange(token_dims)\n",
        "pos_cols_np = pos_cols_np[np.newaxis, :]\n",
        "pos_cols_np = np.power(10000, (2 * (pos_cols_np // 2)) / token_dims)\n",
        "\n",
        "pos_enc_pre_sin = rows_np / pos_cols_np\n",
        "\n",
        "pos_encoding_np = np.zeros(pos_enc_pre_sin.shape)\n",
        "pos_encoding_np[:, 0::2] = np.sin(pos_enc_pre_sin[:, 0::2])\n",
        "pos_encoding_np[:, 1::2] = np.cos(pos_enc_pre_sin[:, 1::2])\n",
        "\n",
        "if (pos_encodings.compare(pos_encoding_np)):\n",
        "  print(\"They are similar!\")\n",
        "else:\n",
        "  print(\"They are not similar!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = \"This is a sentence\"\n",
        "sentence_toks = [0, 1, 2, 3] # Straight forward\n",
        "word2tok = {\"This\" : 0, \"is\" : 1, \"a\" : 2, \"sentence\" : 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "def xavier_uniform(fan_in, fan_out):\n",
        "  return math.sqrt(6 / (fan_in + fan_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "DNS1PI19Tvas"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings=[[ 0.41607213  0.72918266 -0.7984399   0.81226754]\n",
            " [ 0.736365   -0.09292436  0.28980532 -0.67561984]\n",
            " [-0.0515829   0.0228521   0.47834936 -0.35547632]\n",
            " [ 0.37067556 -0.24508198  0.31422633 -0.3602407 ]]\n"
          ]
        }
      ],
      "source": [
        "embeddings = Matrix(vocab_size, token_dims, np.float32, gpu=True)\n",
        "embeddings.alloc_on_gpu()\n",
        "embeddings_scale = xavier_uniform(embeddings.num_rows, embeddings.num_cols)\n",
        "embeddings.init_uniform_rand(embeddings_scale)\n",
        "\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{embeddings=}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.41607213  0.72918266 -0.7984399   0.81226754]\n",
            " [ 0.736365   -0.09292436  0.28980532 -0.67561984]\n",
            " [-0.0515829   0.0228521   0.47834936 -0.35547632]\n",
            " [ 0.37067556 -0.24508198  0.31422633 -0.3602407 ]]\n"
          ]
        }
      ],
      "source": [
        "embeddings.copy_d_to_h()\n",
        "embeddings_np = embeddings.a_host.copy()\n",
        "print(embeddings_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO: Add a function that adds two matrices but has the ability to \"scale\" down matrices based on which one is bigger, etc\n",
        "# Special \"trimmed\" matrix add...\n",
        "kernel_code = \"\"\"\n",
        "// Assumes embedding matrix has been sized such that Dim(embedding_matrix) < Dim(pos_enc)\n",
        "extern \"C\" __global__ void add_pos_enc_and_embed(float* embedding_matrix, float* pos_enc, float* output, int N) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (idx < N) {\n",
        "    output[idx] = embedding_matrix[idx] + pos_enc[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code,\n",
        "                   no_extern_c=True,\n",
        "                   options=[\"-std=c++11\",\n",
        "                           \"-Xcompiler\",\n",
        "                           \"-fPIC\"])\n",
        "\n",
        "add_pos_enc_and_embed = mod.get_function(\"add_pos_enc_and_embed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_w_pos=[[ 0.41607213  1.7291827  -0.7984399   1.8122675 ]\n",
            " [ 1.577836    0.44737792  0.29980516  0.32433015]\n",
            " [ 0.8577146  -0.39329472  0.49834803  0.6443237 ]\n",
            " [ 0.5117956  -1.2350745   0.34422183  0.63930935]]\n"
          ]
        }
      ],
      "source": [
        "embeddings_w_pos = Matrix(embeddings.num_rows, embeddings.num_cols, np.float32, gpu=True)\n",
        "embeddings_w_pos.alloc_on_gpu()\n",
        "add_pos_enc_and_embed(embeddings.a_gpu,\n",
        "                      pos_encodings.a_gpu,\n",
        "                      embeddings_w_pos.a_gpu,\n",
        "                      np.int32(embeddings.num_elements()),\n",
        "                      block=(embeddings.num_elements(), 1, 1))\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{embeddings_w_pos=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_np=array([[ 0.41607213,  0.72918266, -0.7984399 ,  0.81226754],\n",
            "       [ 0.736365  , -0.09292436,  0.28980532, -0.67561984],\n",
            "       [-0.0515829 ,  0.0228521 ,  0.47834936, -0.35547632],\n",
            "       [ 0.37067556, -0.24508198,  0.31422633, -0.3602407 ]],\n",
            "      dtype=float32)\n",
            "trimmed_pos_enc_np=array([[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
            "       [ 0.84147098,  0.54030231,  0.00999983,  0.99995   ],\n",
            "       [ 0.90929743, -0.41614684,  0.01999867,  0.99980001],\n",
            "       [ 0.14112001, -0.9899925 ,  0.0299955 ,  0.99955003]])\n",
            "embeddings_w_pos_np=array([[ 0.41607213,  1.72918266, -0.79843992,  1.81226754],\n",
            "       [ 1.57783601,  0.44737795,  0.29980516,  0.32433016],\n",
            "       [ 0.85771453, -0.39329474,  0.49834802,  0.64432369],\n",
            "       [ 0.51179557, -1.23507447,  0.34422183,  0.63930934]])\n",
            "Embeddings are similar!\n"
          ]
        }
      ],
      "source": [
        "trimmed_pos_enc_np = pos_encoding_np[:4, :]\n",
        "print(f\"{embeddings_np=}\")\n",
        "print(f\"{trimmed_pos_enc_np=}\")\n",
        "embeddings_w_pos_np = embeddings_np + trimmed_pos_enc_np\n",
        "print(f\"{embeddings_w_pos_np=}\")\n",
        "\n",
        "if (embeddings_w_pos.compare(embeddings_w_pos_np)):\n",
        "  print(\"Embeddings are similar!\")\n",
        "else:\n",
        "  print(\"Embeddings not similar!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 56.  62.  68.  74.]\n",
            " [152. 174. 196. 218.]\n",
            " [248. 286. 324. 362.]\n",
            " [344. 398. 452. 506.]]\n"
          ]
        }
      ],
      "source": [
        "test_a = Matrix(4,4,np.float32,gpu=True)\n",
        "test_a.alloc_on_gpu()\n",
        "test_a.init_incremental()\n",
        "\n",
        "test_b = Matrix(4,4,np.float32,gpu=True)\n",
        "test_b.alloc_on_gpu()\n",
        "test_b.init_incremental()\n",
        "\n",
        "test_c = test_a * test_b\n",
        "print(test_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initially: test_c=[[ 56.  62.  68.  74.]\n",
            " [152. 174. 196. 218.]\n",
            " [248. 286. 324. 362.]\n",
            " [344. 398. 452. 506.]]\n",
            "After scalar divide: test_c=[[ 28.  31.  34.  37.]\n",
            " [ 76.  87.  98. 109.]\n",
            " [124. 143. 162. 181.]\n",
            " [172. 199. 226. 253.]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Initially: {test_c=}\")\n",
        "test_c = test_c / 2\n",
        "print(f\"After scalar divide: {test_c=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q=[[ 0.5858841  -0.07326937 -1.5218644   0.3128903 ]\n",
            " [-0.14234573  1.1255311  -0.9151788  -1.2557507 ]\n",
            " [-1.4943337   0.22304492  0.5137239  -0.76285994]\n",
            " [ 0.7072086   1.4134607  -1.5254618   1.6387186 ]]\n",
            "K=[[ 0.5858841  -0.07326937 -1.5218644   0.3128903 ]\n",
            " [-0.14234573  1.1255311  -0.9151788  -1.2557507 ]\n",
            " [-1.4943337   0.22304492  0.5137239  -0.76285994]\n",
            " [ 0.7072086   1.4134607  -1.5254618   1.6387186 ]]\n",
            "V=[[ 0.5858841  -0.07326937 -1.5218644   0.3128903 ]\n",
            " [-0.14234573  1.1255311  -0.9151788  -1.2557507 ]\n",
            " [-1.4943337   0.22304492  0.5137239  -0.76285994]\n",
            " [ 0.7072086   1.4134607  -1.5254618   1.6387186 ]]\n"
          ]
        }
      ],
      "source": [
        "# Embedding matrix = [vocab_size, token_dims]\n",
        "# Technically you can make swap the dimensions of this and it will still work\n",
        "# One way requires a transpose, the other doesn't\n",
        "# Weights: [3 * token_dims, token_dims]\n",
        "\n",
        "#TODO: Make a weight transpose instead for learnings... Even though a bit less efficient...\n",
        "# weights = Matrix(3 * embeddings.num_cols, embeddings.num_cols, np.float32, gpu=True)\n",
        "# weights.alloc_on_gpu()\n",
        "weights_t = Matrix(embeddings_w_pos.num_cols, 3 * embeddings_w_pos.num_cols, np.float32, gpu=True)\n",
        "weights_t.alloc_on_gpu()\n",
        "weights_scale = xavier_uniform(weights_t.num_rows, weights_t.num_cols)\n",
        "weights_t.init_uniform_rand(weights_scale)\n",
        "\n",
        "# QKV matrix = [vocab_size, 3 * token_dims]\n",
        "QKV = embeddings_w_pos * weights_t\n",
        "\n",
        "bias_scale = xavier_uniform(QKV.num_cols, 1)\n",
        "\n",
        "b = Matrix(QKV.num_cols, 1, np.float32, gpu=True)\n",
        "b.alloc_on_gpu()\n",
        "b.init_uniform_rand(bias_scale)\n",
        "\n",
        "QKV_b = Matrix(QKV.num_rows, QKV.num_cols, np.float32, gpu=True)\n",
        "QKV_b.alloc_on_gpu()\n",
        "\n",
        "add_matrix_w_vector(QKV.a_gpu,\n",
        "                    b.a_gpu,\n",
        "                    np.int32(QKV.num_rows),\n",
        "                    np.int32(QKV.num_cols),\n",
        "                    QKV_b.a_gpu,\n",
        "                    block=(QKV.num_cols, QKV.num_rows, 1))\n",
        "\n",
        "Q = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "Q.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(0 * QKV_b.num_cols) / 3)\n",
        "\n",
        "K = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "K.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(1 * QKV_b.num_cols) / 3)\n",
        "\n",
        "V = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "V.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(2 * QKV_b.num_cols) / 3)\n",
        "\n",
        "score_scaled = (Q * K.transpose()) / math.sqrt(Q.num_cols)\n",
        "\n",
        "print(f\"{Q=}\")\n",
        "print(f\"{K=}\")\n",
        "print(f\"{V=}\")\n",
        "# print(f\"{score_scaled=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q_np=array([[ 0.58588406, -0.07326933, -1.52186439,  0.3128903 ],\n",
            "       [ 0.70720858,  1.4134607 , -1.52546181,  1.63871851],\n",
            "       [ 0.10867436,  1.24667903, -1.4293614 ,  1.59489841],\n",
            "       [-0.16197938,  1.14311773, -1.44620626,  1.52932941]])\n",
            "K_np=array([[-0.14234572,  1.12553115, -0.91517874, -1.2557506 ],\n",
            "       [ 1.24368024,  0.12450988,  0.19428861, -1.26649397],\n",
            "       [ 0.98947497, -0.02572972,  0.25539853, -0.84585492],\n",
            "       [ 0.98203293, -0.33542146,  0.57010891, -0.66561129]])\n",
            "V_np=array([[-1.49433365,  0.22304491,  0.51372392, -0.7628599 ],\n",
            "       [-0.52501754,  0.16229238,  0.9234576 , -0.82537725],\n",
            "       [-0.43512996,  0.0794783 ,  0.98639025, -0.64482916],\n",
            "       [-0.07674777, -0.06324649,  1.05018927, -0.44635892]])\n"
          ]
        }
      ],
      "source": [
        "b.copy_d_to_h()\n",
        "b_np = b.a_host.copy()\n",
        "b_np = b_np.T\n",
        "\n",
        "# weights_t_np = np.random.uniform(low=-weights_scale, high=weights_scale, size=(weights_t.num_rows, weights_t.num_cols))\n",
        "weights_t.copy_d_to_h()\n",
        "weights_t_np = weights_t.a_host.copy()\n",
        "\n",
        "QKV_np = embeddings_w_pos_np @ weights_t_np\n",
        "QKV_b_np = QKV_np + b_np\n",
        "\n",
        "split_dim = int(QKV_b_np.shape[1] / 3)\n",
        "\n",
        "Q_np = QKV_b_np[:, : split_dim]\n",
        "K_np = QKV_b_np[:, split_dim : 2 * split_dim]\n",
        "V_np = QKV_b_np[:, 2 * split_dim :]\n",
        "\n",
        "print(f\"{Q_np=}\")\n",
        "print(f\"{K_np=}\")\n",
        "print(f\"{V_np=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_a=[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "Before: test_output=[[0.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]]\n",
            "After: test_output=[[ 6.]\n",
            " [22.]\n",
            " [38.]\n",
            " [54.]]\n"
          ]
        }
      ],
      "source": [
        "test_a = Matrix(4,4,np.float32,gpu=True)\n",
        "test_a.alloc_on_gpu()\n",
        "test_a.init_incremental()\n",
        "\n",
        "test_output = Matrix(4,1,np.float32,gpu=True)\n",
        "test_output.alloc_on_gpu()\n",
        "test_output.init_incremental()\n",
        "\n",
        "print(f\"{test_a=}\")\n",
        "print(f\"Before: {test_output=}\")\n",
        "\n",
        "matrix_row_wise_add(test_a.a_gpu,\n",
        "        np.int32(test_a.num_rows),\n",
        "        np.int32(test_a.num_cols),\n",
        "        test_output.a_gpu,\n",
        "        block=(test_a.num_cols,test_a.num_rows,1),\n",
        "        shared=test_a.num_elements() * test_a.dtype().nbytes)\n",
        "\n",
        "print(f\"After: {test_output=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_scaled_row_sum = Matrix(score_scaled.num_rows, 1, np.float32, gpu=True)\n",
        "score_scaled_row_sum.alloc_on_gpu()\n",
        "\n",
        "matrix_row_wise_add(score_scaled.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_row_sum.a_gpu,\n",
        "        block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "        shared=score_scaled.num_elements() * score_scaled.dtype().nbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_scaled_row_max = Matrix(score_scaled.num_rows, 1, np.float32, gpu=True)\n",
        "score_scaled_row_max.alloc_on_gpu()\n",
        "\n",
        "matrix_row_wise_max(score_scaled.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_row_max.a_gpu,\n",
        "        block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "        shared=score_scaled.num_elements() * score_scaled.dtype().nbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_mat=[[ 1.3813001   0.41700038 -0.95617914  1.572532  ]\n",
            " [ 0.41700038  1.8507723   0.47578433  0.41423714]\n",
            " [-0.95617914  0.47578433  1.564325   -1.3876597 ]\n",
            " [ 1.572532    0.41423714 -1.3876597   3.7552238 ]]\n",
            "score_row_max=[[1.572532 ]\n",
            " [1.8507723]\n",
            " [1.564325 ]\n",
            " [3.7552238]]\n",
            "score_row_sum=[[ 2.4146533 ]\n",
            " [ 3.157794  ]\n",
            " [-0.30372953]\n",
            " [ 4.354333  ]]\n",
            "softmax=array([[ 3.4205365e-01,  1.3040799e-01,  3.3032380e-02,  4.1413814e-01],\n",
            "       [ 7.5498268e-02,  3.1667677e-01,  8.0069385e-02,  7.5289935e-02],\n",
            "       [-2.6477197e-01, -1.1085768e+00, -3.2924030e+00, -1.7198174e-01],\n",
            "       [ 2.5890920e-02,  8.1302943e-03,  1.3413822e-03,  2.2965631e-01]],\n",
            "      dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def check_softmax(score_mat, score_row_max, score_row_sum):\n",
        "  score_mat.copy_d_to_h()\n",
        "  score_row_max.copy_d_to_h()\n",
        "  score_row_sum.copy_d_to_h()\n",
        "\n",
        "  print(f\"{score_mat=}\")\n",
        "  print(f\"{score_row_max=}\")\n",
        "  print(f\"{score_row_sum=}\")\n",
        "\n",
        "  scores = score_mat.a_host / 1.0\n",
        "\n",
        "  exp_score = np.exp(scores - score_row_max.a_host)\n",
        "  softmax = exp_score / score_row_sum.a_host\n",
        "\n",
        "  print(f\"{softmax=}\")\n",
        "\n",
        "check_softmax(score_scaled, score_scaled_row_max, score_scaled_row_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled=[[ 1.3813001   0.41700038 -0.95617914  1.572532  ]\n",
            " [ 0.41700038  1.8507723   0.47578433  0.41423714]\n",
            " [-0.95617914  0.47578433  1.564325   -1.3876597 ]\n",
            " [ 1.572532    0.41423714 -1.3876597   3.7552238 ]]\n",
            "score_scaled_row_max=[[1.572532 ]\n",
            " [1.8507723]\n",
            " [1.564325 ]\n",
            " [3.7552238]]\n",
            "score_scaled_row_sum=[[ 2.4146533 ]\n",
            " [ 3.157794  ]\n",
            " [-0.30372953]\n",
            " [ 4.354333  ]]\n",
            "score_scaled_softmaxed=[[1.1846696e+06 3.8521662e+05 6.3682119e+05 4.5485572e+05]\n",
            " [4.0000000e+00 5.0000000e+00 6.0000000e+00 7.0000000e+00]\n",
            " [8.0000000e+00 9.0000000e+00 1.0000000e+01 1.1000000e+01]\n",
            " [1.2000000e+01 1.3000000e+01 1.4000000e+01 1.5000000e+01]]\n"
          ]
        }
      ],
      "source": [
        "score_scaled_softmaxed = Matrix(score_scaled.num_rows, score_scaled.num_cols, np.float32, gpu=True)\n",
        "score_scaled_softmaxed.alloc_on_gpu()\n",
        "\n",
        "print(f\"{score_scaled=}\")\n",
        "print(f\"{score_scaled_row_max=}\")\n",
        "print(f\"{score_scaled_row_sum=}\")\n",
        "\n",
        "softmax(score_scaled.a_gpu,\n",
        "        score_scaled_row_max.a_gpu,\n",
        "        score_scaled_row_sum.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_softmaxed.a_gpu,\n",
        "        block=(score_scaled_softmaxed.num_cols, score_scaled_softmaxed.num_rows, 1))\n",
        "\n",
        "print(f\"{score_scaled_softmaxed=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attention_output=[[ 9.2996143e+03  1.1317338e+06 -2.5221632e+06  1.4651078e+05]\n",
            " [-2.3837347e+00  1.6567074e+01 -1.8259239e+01  1.8666782e+00]\n",
            " [-3.7580822e+00  2.7322142e+01 -3.2054363e+01  1.5986719e+00]\n",
            " [-5.1324291e+00  3.8077209e+01 -4.5849487e+01  1.3306646e+00]]\n"
          ]
        }
      ],
      "source": [
        "# print(score_scaled_softmaxed.shape)\n",
        "# print(V.shape)\n",
        "\n",
        "attention_output = score_scaled_softmaxed * V\n",
        "print(f\"{attention_output=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_w_pos=[[ 0.41607213  1.7291827  -0.7984399   1.8122675 ]\n",
            " [ 1.577836    0.44737792  0.29980516  0.32433015]\n",
            " [ 0.8577146  -0.39329472  0.49834803  0.6443237 ]\n",
            " [ 0.5117956  -1.2350745   0.34422183  0.63930935]]\n",
            "attention_output=[[ 9.2996143e+03  1.1317338e+06 -2.5221632e+06  1.4651078e+05]\n",
            " [-2.3837347e+00  1.6567074e+01 -1.8259239e+01  1.8666782e+00]\n",
            " [-3.7580822e+00  2.7322142e+01 -3.2054363e+01  1.5986719e+00]\n",
            " [-5.1324291e+00  3.8077209e+01 -4.5849487e+01  1.3306646e+00]]\n",
            "[[ 9.3000303e+03  1.1317355e+06 -2.5221640e+06  1.4651259e+05]\n",
            " [-8.0589867e-01  1.7014452e+01 -1.7959435e+01  2.1910083e+00]\n",
            " [-2.9003675e+00  2.6928846e+01 -3.1556015e+01  2.2429957e+00]\n",
            " [-4.6206336e+00  3.6842136e+01 -4.5505264e+01  1.9699740e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"{embeddings_w_pos=}\")\n",
        "print(f\"{attention_output=}\")\n",
        "add = embeddings_w_pos + attention_output\n",
        "print(f\"{add}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNOSc2A+76qSEFerkYh9pBl",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
