{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 578,
      "metadata": {
        "id": "sc4gxOF5TVJP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from kernel_lib import *\n",
        "from matrix import Matrix\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 579,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = [\"This\", \"is\", \"a\", \"sentence\"]\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "pos_enc_sequence_len = 10\n",
        "token_dims = vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 580,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pos_encodings=[[ 1.00000000e+00  0.00000000e+00  9.99999975e-05  0.00000000e+00]\n",
            " [ 5.40302277e-01  8.41471016e-01  5.40302281e-05  8.41471046e-05]\n",
            " [-4.16146815e-01  9.09297466e-01 -4.16146831e-05  9.09297451e-05]\n",
            " [-9.89992499e-01  1.41120002e-01 -9.89992477e-05  1.41119999e-05]\n",
            " [-6.53643668e-01 -7.56802499e-01 -6.53643656e-05 -7.56802474e-05]\n",
            " [ 2.83662170e-01 -9.58924294e-01  2.83662175e-05 -9.58924284e-05]\n",
            " [ 9.60170269e-01 -2.79415488e-01  9.60170291e-05 -2.79415490e-05]\n",
            " [ 7.53902256e-01  6.56986594e-01  7.53902277e-05  6.56986595e-05]\n",
            " [-1.45500034e-01  9.89358246e-01 -1.45500035e-05  9.89358232e-05]\n",
            " [-9.11130250e-01  4.12118495e-01 -9.11130264e-05  4.12118497e-05]]\n"
          ]
        }
      ],
      "source": [
        "pos_encodings = Matrix(pos_enc_sequence_len, token_dims, np.float32, gpu=True)\n",
        "pos_encodings.alloc_on_gpu()\n",
        "gen_pos_encodings(pos_encodings.a_gpu,\n",
        "                  np.int32(pos_encodings.num_rows),\n",
        "                  np.int32(pos_encodings.num_cols),\n",
        "                  block=(pos_encodings.num_cols, pos_encodings.num_rows, 1))\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{pos_encodings=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 581,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = \"This is a sentence\"\n",
        "sentence_toks = [0, 1, 2, 3] # Straight forward\n",
        "word2tok = {\"This\" : 0, \"is\" : 1, \"a\" : 2, \"sentence\" : 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 582,
      "metadata": {
        "id": "DNS1PI19Tvas"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings=[[ 0.41607213  0.72918266 -0.7984399   0.81226754]\n",
            " [ 0.736365   -0.09292436  0.28980532 -0.67561984]\n",
            " [-0.0515829   0.0228521   0.47834936 -0.35547632]\n",
            " [ 0.37067556 -0.24508198  0.31422633 -0.3602407 ]]\n"
          ]
        }
      ],
      "source": [
        "embeddings = Matrix(vocab_size, token_dims, np.float32, gpu=True)\n",
        "embeddings.alloc_on_gpu()\n",
        "embeddings.init_uniform_rand(math.sqrt(6.0 / (embeddings.num_rows + embeddings.num_cols)))\n",
        "\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{embeddings=}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 583,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO: Add a function that adds two matrices but has the ability to \"scale\" down matrices based on which one is bigger, etc\n",
        "# Special \"trimmed\" matrix add...\n",
        "kernel_code = \"\"\"\n",
        "// Assumes embedding matrix has been sized such that Dim(embedding_matrix) < Dim(pos_enc)\n",
        "extern \"C\" __global__ void add_pos_enc_and_embed(float* embedding_matrix, float* pos_enc, float* output, int N) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (idx < N) {\n",
        "    output[idx] = embedding_matrix[idx] + pos_enc[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code,\n",
        "                   no_extern_c=True,\n",
        "                   options=[\"-std=c++11\",\n",
        "                           \"-Xcompiler\",\n",
        "                           \"-fPIC\"])\n",
        "\n",
        "add_pos_enc_and_embed = mod.get_function(\"add_pos_enc_and_embed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 584,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_w_pos=[[ 1.4160721   0.72918266 -0.7983399   0.81226754]\n",
            " [ 1.2766674   0.74854666  0.28985935 -0.6755357 ]\n",
            " [-0.46772972  0.9321496   0.47830775 -0.3553854 ]\n",
            " [-0.61931694 -0.10396197  0.31412733 -0.36022657]]\n"
          ]
        }
      ],
      "source": [
        "embeddings_w_pos = Matrix(embeddings.num_rows, embeddings.num_cols, np.float32, gpu=True)\n",
        "embeddings_w_pos.alloc_on_gpu()\n",
        "add_pos_enc_and_embed(embeddings.a_gpu,\n",
        "                      pos_encodings.a_gpu,\n",
        "                      embeddings_w_pos.a_gpu,\n",
        "                      np.int32(embeddings.num_elements()),\n",
        "                      block=(embeddings.num_elements(), 1, 1))\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{embeddings_w_pos=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 585,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 56.  62.  68.  74.]\n",
            " [152. 174. 196. 218.]\n",
            " [248. 286. 324. 362.]\n",
            " [344. 398. 452. 506.]]\n"
          ]
        }
      ],
      "source": [
        "test_a = Matrix(4,4,np.float32,gpu=True)\n",
        "test_a.alloc_on_gpu()\n",
        "test_a.init_incremental()\n",
        "\n",
        "test_b = Matrix(4,4,np.float32,gpu=True)\n",
        "test_b.alloc_on_gpu()\n",
        "test_b.init_incremental()\n",
        "\n",
        "test_c = test_a * test_b\n",
        "print(test_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 586,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initially: test_c=[[ 56.  62.  68.  74.]\n",
            " [152. 174. 196. 218.]\n",
            " [248. 286. 324. 362.]\n",
            " [344. 398. 452. 506.]]\n",
            "After scalar divide: test_c=[[ 28.  31.  34.  37.]\n",
            " [ 76.  87.  98. 109.]\n",
            " [124. 143. 162. 181.]\n",
            " [172. 199. 226. 253.]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Initially: {test_c=}\")\n",
        "test_c = test_c / 2\n",
        "print(f\"After scalar divide: {test_c=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 587,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled=[[ 1.1225320e+11 -2.0338322e+07 -3.3078220e+07  1.0120327e+11]\n",
            " [-2.0338322e+07  3.8308286e+03  6.2350864e+03 -1.8336256e+07]\n",
            " [-3.3078220e+07  6.2350864e+03  1.0151939e+04 -2.9822062e+07]\n",
            " [ 1.0120327e+11 -1.8336256e+07 -2.9822062e+07  9.1241071e+10]]\n"
          ]
        }
      ],
      "source": [
        "# Embedding matrix = [vocab_size, token_dims]\n",
        "# Technically you can make swap the dimensions of this and it will still work\n",
        "# One way requires a transpose, the other doesn't\n",
        "# Weights: [3 * token_dims, token_dims]\n",
        "\n",
        "#TODO: Make a weight transpose instead for learnings... Even though a bit less efficient...\n",
        "# weights = Matrix(3 * embeddings.num_cols, embeddings.num_cols, np.float32, gpu=True)\n",
        "# weights.alloc_on_gpu()\n",
        "weights_t = Matrix(embeddings_w_pos.num_cols, 3 * embeddings_w_pos.num_cols, np.float32, gpu=True)\n",
        "weights_t.alloc_on_gpu()\n",
        "\n",
        "# QKV matrix = [vocab_size, 3 * token_dims]\n",
        "QKV = Matrix(embeddings_w_pos.num_rows, weights_t.num_cols, np.float32, gpu=True)\n",
        "QKV.alloc_on_gpu()\n",
        "\n",
        "regular_matmul(embeddings_w_pos.a_gpu,\n",
        "               weights_t.a_gpu,\n",
        "               np.int32(QKV.num_rows),\n",
        "               np.int32(QKV.num_cols),\n",
        "               np.int32(embeddings_w_pos.num_cols),\n",
        "               QKV.a_gpu,\n",
        "               block=(QKV.num_cols, QKV.num_rows, 1))\n",
        "\n",
        "b = Matrix(QKV.num_cols, 1, np.float32, gpu=True)\n",
        "b.alloc_on_gpu()\n",
        "# TODO: Fix the scale here..?\n",
        "b.init_uniform_rand(math.sqrt(6.0 / (embeddings.num_rows + embeddings.num_cols)))\n",
        "\n",
        "QKV_b = Matrix(QKV.num_rows, QKV.num_cols, np.float32, gpu=True)\n",
        "QKV_b.alloc_on_gpu()\n",
        "\n",
        "add_matrix_w_vector(QKV.a_gpu,\n",
        "                    b.a_gpu,\n",
        "                    np.int32(QKV.num_rows),\n",
        "                    np.int32(QKV.num_cols),\n",
        "                    QKV_b.a_gpu,\n",
        "                    block=(QKV.num_cols, QKV.num_rows, 1))\n",
        "\n",
        "Q = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "Q.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(0 * QKV_b.num_cols) / 3)\n",
        "\n",
        "K = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "K.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(1 * QKV_b.num_cols) / 3)\n",
        "\n",
        "V = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "V.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(2 * QKV_b.num_cols) / 3)\n",
        "\n",
        "score_scaled = (Q * K.transpose()) / math.sqrt(Q.num_cols)\n",
        "\n",
        "print(f\"{score_scaled=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 588,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_a=[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "Before: test_output=[[0.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]]\n",
            "After: test_output=[[ 6.]\n",
            " [22.]\n",
            " [38.]\n",
            " [54.]]\n"
          ]
        }
      ],
      "source": [
        "test_a = Matrix(4,4,np.float32,gpu=True)\n",
        "test_a.alloc_on_gpu()\n",
        "test_a.init_incremental()\n",
        "\n",
        "test_output = Matrix(4,1,np.float32,gpu=True)\n",
        "test_output.alloc_on_gpu()\n",
        "test_output.init_incremental()\n",
        "\n",
        "print(f\"{test_a=}\")\n",
        "print(f\"Before: {test_output=}\")\n",
        "\n",
        "matrix_row_wise_add(test_a.a_gpu,\n",
        "        np.int32(test_a.num_rows),\n",
        "        np.int32(test_a.num_cols),\n",
        "        test_output.a_gpu,\n",
        "        block=(test_a.num_cols,test_a.num_rows,1),\n",
        "        shared=test_a.num_elements() * test_a.dtype().nbytes)\n",
        "\n",
        "print(f\"After: {test_output=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 589,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score=[[329311.47 214482.02 353902.7  328667.47]\n",
            " [214482.02 139694.45 230497.36 214062.28]\n",
            " [353902.7  230497.36 380346.25 353212.4 ]\n",
            " [328667.47 214062.28 353212.4  328024.97]]\n",
            "score_scaled=[[ 1.1225320e+11 -2.0338322e+07 -3.3078220e+07  1.0120327e+11]\n",
            " [-2.0338322e+07  3.8308286e+03  6.2350864e+03 -1.8336256e+07]\n",
            " [-3.3078220e+07  6.2350864e+03  1.0151939e+04 -2.9822062e+07]\n",
            " [ 1.0120327e+11 -1.8336256e+07 -2.9822062e+07  9.1241071e+10]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"{score=}\")\n",
        "print(f\"{score_scaled=}\")\n",
        "\n",
        "score_scaled_row_sum = Matrix(score_scaled.num_rows, 1, np.float32, gpu=True)\n",
        "score_scaled_row_sum.alloc_on_gpu()\n",
        "\n",
        "matrix_row_wise_add(score_scaled.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_row_sum.a_gpu,\n",
        "        block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "        shared=score_scaled.num_elements() * score_scaled.dtype().nbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 590,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_scaled_row_max = Matrix(score_scaled.num_rows, 1, np.float32, gpu=True)\n",
        "score_scaled_row_max.alloc_on_gpu()\n",
        "\n",
        "matrix_row_wise_max(score_scaled.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_row_max.a_gpu,\n",
        "        block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "        shared=score_scaled.num_elements() * score_scaled.dtype().nbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 591,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocating on host!\n",
            "Allocating on host!\n",
            "Allocating on host!\n",
            "score_mat=[[ 1.1225320e+11 -2.0338322e+07 -3.3078220e+07  1.0120327e+11]\n",
            " [-2.0338322e+07  3.8308286e+03  6.2350864e+03 -1.8336256e+07]\n",
            " [-3.3078220e+07  6.2350864e+03  1.0151939e+04 -2.9822062e+07]\n",
            " [ 1.0120327e+11 -1.8336256e+07 -2.9822062e+07  9.1241071e+10]]\n",
            "score_row_max=[[1.1225320e+11]\n",
            " [6.2350864e+03]\n",
            " [1.0151939e+04]\n",
            " [1.0120327e+11]]\n",
            "score_row_sum=[[ 2.1340304e+11]\n",
            " [-3.8664512e+07]\n",
            " [-6.2883896e+07]\n",
            " [ 1.9239620e+11]]\n",
            "softmax=array([[ 4.6859686e-12,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [-0.0000000e+00, -0.0000000e+00, -2.5863510e-08, -0.0000000e+00],\n",
            "       [-0.0000000e+00, -0.0000000e+00, -1.5902323e-08, -0.0000000e+00],\n",
            "       [ 5.1976080e-12,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
            "      dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def check_softmax(score_mat, score_row_max, score_row_sum):\n",
        "  score_mat.copy_d_to_h()\n",
        "  score_row_max.copy_d_to_h()\n",
        "  score_row_sum.copy_d_to_h()\n",
        "\n",
        "  print(f\"{score_mat=}\")\n",
        "  print(f\"{score_row_max=}\")\n",
        "  print(f\"{score_row_sum=}\")\n",
        "\n",
        "  scores = score_mat.a_host / 1.0\n",
        "\n",
        "  exp_score = np.exp(scores - score_row_max.a_host)\n",
        "  softmax = exp_score / score_row_sum.a_host\n",
        "\n",
        "  print(f\"{softmax=}\")\n",
        "\n",
        "check_softmax(score_scaled, score_scaled_row_max, score_scaled_row_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 592,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled=[[ 1.1225320e+11 -2.0338322e+07 -3.3078220e+07  1.0120327e+11]\n",
            " [-2.0338322e+07  3.8308286e+03  6.2350864e+03 -1.8336256e+07]\n",
            " [-3.3078220e+07  6.2350864e+03  1.0151939e+04 -2.9822062e+07]\n",
            " [ 1.0120327e+11 -1.8336256e+07 -2.9822062e+07  9.1241071e+10]]\n",
            "score_scaled_row_max=[[1.1225320e+11]\n",
            " [6.2350864e+03]\n",
            " [1.0151939e+04]\n",
            " [1.0120327e+11]]\n",
            "score_scaled_row_sum=[[ 2.1340304e+11]\n",
            " [-3.8664512e+07]\n",
            " [-6.2883896e+07]\n",
            " [ 1.9239620e+11]]\n",
            "score_scaled_softmaxed=[[1.4168753e+05 2.1128656e+05 3.4863278e+05 4.0321256e+05]\n",
            " [4.0000000e+00 5.0000000e+00 6.0000000e+00 7.0000000e+00]\n",
            " [8.0000000e+00 9.0000000e+00 1.0000000e+01 1.1000000e+01]\n",
            " [1.2000000e+01 1.3000000e+01 1.4000000e+01 1.5000000e+01]]\n"
          ]
        }
      ],
      "source": [
        "score_scaled_softmaxed = Matrix(score_scaled.num_rows, score_scaled.num_cols, np.float32, gpu=True)\n",
        "score_scaled_softmaxed.alloc_on_gpu()\n",
        "\n",
        "print(f\"{score_scaled=}\")\n",
        "print(f\"{score_scaled_row_max=}\")\n",
        "print(f\"{score_scaled_row_sum=}\")\n",
        "\n",
        "softmax(score_scaled.a_gpu,\n",
        "        score_scaled_row_max.a_gpu,\n",
        "        score_scaled_row_sum.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_softmaxed.a_gpu,\n",
        "        block=(score_scaled_softmaxed.num_cols, score_scaled_softmaxed.num_rows, 1))\n",
        "\n",
        "print(f\"{score_scaled_softmaxed=}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNOSc2A+76qSEFerkYh9pBl",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
