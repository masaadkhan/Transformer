{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "sc4gxOF5TVJP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from kernel_lib import *\n",
        "from matrix import Matrix\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = [\"This\", \"is\", \"a\", \"sentence\"]\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "pos_enc_sequence_len = 10\n",
        "token_dims = vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.          1.          0.          1.        ]\n",
            " [ 0.841471    0.5403023   0.00999983  0.99995   ]\n",
            " [ 0.90929747 -0.4161468   0.01999867  0.9998    ]\n",
            " [ 0.14112    -0.9899925   0.0299955   0.99955004]\n",
            " [-0.7568025  -0.65364367  0.03998933  0.9992001 ]\n",
            " [-0.9589243   0.28366217  0.04997917  0.99875027]\n",
            " [-0.2794155   0.96017027  0.059964    0.99820054]\n",
            " [ 0.6569866   0.75390226  0.06994285  0.997551  ]\n",
            " [ 0.98935825 -0.14550003  0.07991469  0.99680173]\n",
            " [ 0.4121185  -0.91113025  0.08987855  0.9959527 ]]\n"
          ]
        }
      ],
      "source": [
        "pos_encodings = Matrix(pos_enc_sequence_len, token_dims, np.float32, gpu=True)\n",
        "pos_encodings.alloc_on_gpu()\n",
        "gen_pos_encodings(pos_encodings.a_gpu,\n",
        "                  np.int32(pos_encodings.num_rows),\n",
        "                  np.int32(pos_encodings.num_cols),\n",
        "                  block=(pos_encodings.num_cols, pos_encodings.num_rows, 1))\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(pos_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "They are similar!\n"
          ]
        }
      ],
      "source": [
        "rows_np = np.arange(pos_enc_sequence_len)\n",
        "rows_np = rows_np[:, np.newaxis]\n",
        "\n",
        "pos_cols_np = np.arange(token_dims)\n",
        "pos_cols_np = pos_cols_np[np.newaxis, :]\n",
        "pos_cols_np = np.power(10000, (2 * (pos_cols_np // 2)) / token_dims)\n",
        "\n",
        "pos_enc_pre_sin = rows_np / pos_cols_np\n",
        "\n",
        "pos_encoding_np = np.zeros(pos_enc_pre_sin.shape)\n",
        "pos_encoding_np[:, 0::2] = np.sin(pos_enc_pre_sin[:, 0::2])\n",
        "pos_encoding_np[:, 1::2] = np.cos(pos_enc_pre_sin[:, 1::2])\n",
        "\n",
        "if (pos_encodings.compare(pos_encoding_np)):\n",
        "  print(\"They are similar!\")\n",
        "else:\n",
        "  print(\"They are not similar!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = \"This is a sentence\"\n",
        "sentence_toks = [0, 1, 2, 3] # Straight forward\n",
        "word2tok = {\"This\" : 0, \"is\" : 1, \"a\" : 2, \"sentence\" : 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [],
      "source": [
        "def xavier_uniform(fan_in, fan_out):\n",
        "  return math.sqrt(6 / (fan_in + fan_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {
        "id": "DNS1PI19Tvas"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings=[[ 0.41607213  0.72918266 -0.7984399   0.81226754]\n",
            " [ 0.736365   -0.09292436  0.28980532 -0.67561984]\n",
            " [-0.0515829   0.0228521   0.47834936 -0.35547632]\n",
            " [ 0.37067556 -0.24508198  0.31422633 -0.3602407 ]]\n"
          ]
        }
      ],
      "source": [
        "embeddings = Matrix(vocab_size, token_dims, np.float32, gpu=True)\n",
        "embeddings.alloc_on_gpu()\n",
        "embeddings_scale = xavier_uniform(embeddings.num_rows, embeddings.num_cols)\n",
        "embeddings.init_uniform_rand(embeddings_scale)\n",
        "\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{embeddings=}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.41607213  0.72918266 -0.7984399   0.81226754]\n",
            " [ 0.736365   -0.09292436  0.28980532 -0.67561984]\n",
            " [-0.0515829   0.0228521   0.47834936 -0.35547632]\n",
            " [ 0.37067556 -0.24508198  0.31422633 -0.3602407 ]]\n"
          ]
        }
      ],
      "source": [
        "embeddings.copy_d_to_h()\n",
        "embeddings_np = embeddings.a_host.copy()\n",
        "print(embeddings_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO: Add a function that adds two matrices but has the ability to \"scale\" down matrices based on which one is bigger, etc\n",
        "# Special \"trimmed\" matrix add...\n",
        "kernel_code = \"\"\"\n",
        "// Assumes embedding matrix has been sized such that Dim(embedding_matrix) < Dim(pos_enc)\n",
        "extern \"C\" __global__ void add_pos_enc_and_embed(float* embedding_matrix, float* pos_enc, float* output, int N) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (idx < N) {\n",
        "    output[idx] = embedding_matrix[idx] + pos_enc[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code,\n",
        "                   no_extern_c=True,\n",
        "                   options=[\"-std=c++11\",\n",
        "                           \"-Xcompiler\",\n",
        "                           \"-fPIC\"])\n",
        "\n",
        "add_pos_enc_and_embed = mod.get_function(\"add_pos_enc_and_embed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_w_pos=[[ 0.41607213  1.7291827  -0.7984399   1.8122675 ]\n",
            " [ 1.577836    0.44737792  0.29980516  0.32433015]\n",
            " [ 0.8577146  -0.39329472  0.49834803  0.6443237 ]\n",
            " [ 0.5117956  -1.2350745   0.34422183  0.63930935]]\n"
          ]
        }
      ],
      "source": [
        "embeddings_w_pos = Matrix(embeddings.num_rows, embeddings.num_cols, np.float32, gpu=True)\n",
        "embeddings_w_pos.alloc_on_gpu()\n",
        "add_pos_enc_and_embed(embeddings.a_gpu,\n",
        "                      pos_encodings.a_gpu,\n",
        "                      embeddings_w_pos.a_gpu,\n",
        "                      np.int32(embeddings.num_elements()),\n",
        "                      block=(embeddings.num_elements(), 1, 1))\n",
        "cuda.Context.synchronize()\n",
        "\n",
        "print(f\"{embeddings_w_pos=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings are similar!\n"
          ]
        }
      ],
      "source": [
        "trimmed_pos_enc_np = pos_encoding_np[:4, :]\n",
        "embeddings_w_pos_np = embeddings_np + trimmed_pos_enc_np\n",
        "\n",
        "if (embeddings_w_pos.compare(embeddings_w_pos_np)):\n",
        "  print(\"Embeddings are similar!\")\n",
        "else:\n",
        "  print(f\"{embeddings_np=}\")\n",
        "  print(f\"{trimmed_pos_enc_np=}\")\n",
        "  print(f\"{embeddings_w_pos_np=}\")\n",
        "  print(\"Embeddings not similar!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 56.  62.  68.  74.]\n",
            " [152. 174. 196. 218.]\n",
            " [248. 286. 324. 362.]\n",
            " [344. 398. 452. 506.]]\n"
          ]
        }
      ],
      "source": [
        "test_a = Matrix(4,4,np.float32,gpu=True)\n",
        "test_a.alloc_on_gpu()\n",
        "test_a.init_incremental()\n",
        "\n",
        "test_b = Matrix(4,4,np.float32,gpu=True)\n",
        "test_b.alloc_on_gpu()\n",
        "test_b.init_incremental()\n",
        "\n",
        "test_c = test_a * test_b\n",
        "print(test_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Returning the cached matrix value!\n",
            "Initially: test_c=[[ 56.  62.  68.  74.]\n",
            " [152. 174. 196. 218.]\n",
            " [248. 286. 324. 362.]\n",
            " [344. 398. 452. 506.]]\n",
            "After scalar divide: test_c=[[ 28.  31.  34.  37.]\n",
            " [ 76.  87.  98. 109.]\n",
            " [124. 143. 162. 181.]\n",
            " [172. 199. 226. 253.]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Initially: {test_c=}\")\n",
        "test_c = test_c / 2\n",
        "print(f\"After scalar divide: {test_c=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embedding matrix = [vocab_size, token_dims]\n",
        "# Technically you can make swap the dimensions of this and it will still work\n",
        "# One way requires a transpose, the other doesn't\n",
        "# Weights: [3 * token_dims, token_dims]\n",
        "\n",
        "#TODO: Make a weight transpose instead for learnings... Even though a bit less efficient...\n",
        "# weights = Matrix(3 * embeddings.num_cols, embeddings.num_cols, np.float32, gpu=True)\n",
        "# weights.alloc_on_gpu()\n",
        "weights_t = Matrix(embeddings_w_pos.num_cols, 3 * embeddings_w_pos.num_cols, np.float32, gpu=True)\n",
        "weights_t.alloc_on_gpu()\n",
        "weights_scale = xavier_uniform(weights_t.num_rows, weights_t.num_cols)\n",
        "weights_t.init_uniform_rand(weights_scale)\n",
        "\n",
        "# QKV matrix = [vocab_size, 3 * token_dims]\n",
        "QKV = embeddings_w_pos * weights_t\n",
        "\n",
        "bias_scale = xavier_uniform(QKV.num_cols, 1)\n",
        "\n",
        "b = Matrix(QKV.num_cols, 1, np.float32, gpu=True)\n",
        "b.alloc_on_gpu()\n",
        "b.init_uniform_rand(bias_scale)\n",
        "\n",
        "QKV_b = Matrix(QKV.num_rows, QKV.num_cols, np.float32, gpu=True)\n",
        "QKV_b.alloc_on_gpu()\n",
        "\n",
        "add_matrix_w_vector(QKV.a_gpu,\n",
        "                    b.a_gpu,\n",
        "                    np.int32(QKV.num_rows),\n",
        "                    np.int32(QKV.num_cols),\n",
        "                    QKV_b.a_gpu,\n",
        "                    block=(QKV.num_cols, QKV.num_rows, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QKV_b=[[ 0.5858841  -0.07326937 -1.5218644   0.3128903  -0.14234573  1.1255311\n",
            "  -0.9151788  -1.2557507  -1.4943337   0.22304492  0.5137239  -0.76285994]\n",
            " [ 0.7072086   1.4134607  -1.5254618   1.6387186   1.2436802   0.12450986\n",
            "   0.19428861 -1.266494   -0.5250175   0.16229238  0.92345756 -0.8253772 ]\n",
            " [ 0.10867439  1.2466791  -1.4293613   1.5948985   0.989475   -0.02572972\n",
            "   0.2553985  -0.845855   -0.43513     0.07947831  0.9863903  -0.64482915]\n",
            " [-0.16197938  1.1431178  -1.4462063   1.5293294   0.98203295 -0.33542147\n",
            "   0.57010895 -0.66561127 -0.07674776 -0.0632465   1.0501893  -0.44635892]]\n",
            "QKV_b_np=array([[ 0.58588406, -0.07326933, -1.52186439,  0.3128903 , -0.14234572,\n",
            "         1.12553115, -0.91517874, -1.2557506 , -1.49433365,  0.22304491,\n",
            "         0.51372392, -0.7628599 ],\n",
            "       [ 0.70720858,  1.4134607 , -1.52546181,  1.63871851,  1.24368024,\n",
            "         0.12450988,  0.19428861, -1.26649397, -0.52501754,  0.16229238,\n",
            "         0.9234576 , -0.82537725],\n",
            "       [ 0.10867436,  1.24667903, -1.4293614 ,  1.59489841,  0.98947497,\n",
            "        -0.02572972,  0.25539853, -0.84585492, -0.43512996,  0.0794783 ,\n",
            "         0.98639025, -0.64482916],\n",
            "       [-0.16197938,  1.14311773, -1.44620626,  1.52932941,  0.98203293,\n",
            "        -0.33542146,  0.57010891, -0.66561129, -0.07674777, -0.06324649,\n",
            "         1.05018927, -0.44635892]])\n",
            "QKV_b not similar!\n"
          ]
        }
      ],
      "source": [
        "b.copy_d_to_h()\n",
        "b_np = b.a_host.copy()\n",
        "b_np = b_np.T\n",
        "\n",
        "# weights_t_np = np.random.uniform(low=-weights_scale, high=weights_scale, size=(weights_t.num_rows, weights_t.num_cols))\n",
        "weights_t.copy_d_to_h()\n",
        "weights_t_np = weights_t.a_host.copy()\n",
        "\n",
        "QKV_np = embeddings_w_pos_np @ weights_t_np\n",
        "QKV_b_np = QKV_np + b_np\n",
        "\n",
        "if (not QKV_b.compare(QKV_b_np)):\n",
        "  print(\"QKV_b are similar!\")\n",
        "else:\n",
        "  print(f\"{QKV_b=}\")\n",
        "  print(f\"{QKV_b_np=}\")\n",
        "  print(\"QKV_b not similar!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "small_1=[[ 0.  1.  2.  3.]\n",
            " [12. 13. 14. 15.]\n",
            " [24. 25. 26. 27.]\n",
            " [36. 37. 38. 39.]]\n",
            "small_2=[[ 0.  1.  2.  3.]\n",
            " [12. 13. 14. 15.]\n",
            " [24. 25. 26. 27.]\n",
            " [36. 37. 38. 39.]]\n",
            "small_3=[[ 0.  1.  2.  3.]\n",
            " [12. 13. 14. 15.]\n",
            " [24. 25. 26. 27.]\n",
            " [36. 37. 38. 39.]]\n"
          ]
        }
      ],
      "source": [
        "test_big_matrix = Matrix(4, 12, np.float32, gpu=True)\n",
        "test_big_matrix.alloc_on_gpu()\n",
        "test_big_matrix.init_incremental()\n",
        "\n",
        "small_1 = Matrix(4, 4, np.float32, gpu=True)\n",
        "small_1.set_gpu_matrix(test_big_matrix.a_gpu, stride=test_big_matrix.num_cols, start_idx=(0 * test_big_matrix.num_cols) / 3)\n",
        "\n",
        "small_2 = Matrix(4, 4, np.float32, gpu=True)\n",
        "small_2.set_gpu_matrix(test_big_matrix.a_gpu, stride=test_big_matrix.num_cols, start_idx=(0 * test_big_matrix.num_cols) / 3)\n",
        "\n",
        "small_3 = Matrix(4, 4, np.float32, gpu=True)\n",
        "small_3.set_gpu_matrix(test_big_matrix.a_gpu, stride=test_big_matrix.num_cols, start_idx=(0 * test_big_matrix.num_cols) / 3)\n",
        "\n",
        "print(f\"{small_1=}\")\n",
        "print(f\"{small_2=}\")\n",
        "print(f\"{small_3=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {},
      "outputs": [],
      "source": [
        "Q = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "Q.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(0 * QKV_b.num_cols) / 3)\n",
        "\n",
        "K = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "K.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(1 * QKV_b.num_cols) / 3)\n",
        "\n",
        "V = Matrix(QKV_b.num_rows, QKV_b.num_cols / 3, np.float32, gpu=True)\n",
        "V.set_gpu_matrix(QKV_b.a_gpu, stride=QKV_b.num_cols, start_idx=(2 * QKV_b.num_cols) / 3)\n",
        "\n",
        "score_scaled = (Q * K.transpose()) / math.sqrt(Q.num_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q=[[ 0.5858841  -0.07326937 -1.5218644   0.3128903 ]\n",
            " [ 0.7072086   1.4134607  -1.5254618   1.6387186 ]\n",
            " [ 0.10867439  1.2466791  -1.4293613   1.5948985 ]\n",
            " [-0.16197938  1.1431178  -1.4462063   1.5293294 ]]\n",
            "Q_np=array([[ 0.58588406, -0.07326933, -1.52186439,  0.3128903 ],\n",
            "       [ 0.70720858,  1.4134607 , -1.52546181,  1.63871851],\n",
            "       [ 0.10867436,  1.24667903, -1.4293614 ,  1.59489841],\n",
            "       [-0.16197938,  1.14311773, -1.44620626,  1.52932941]])\n",
            "Q is not similar\n",
            "K=[[-0.14234573  1.1255311  -0.9151788  -1.2557507 ]\n",
            " [ 1.2436802   0.12450986  0.19428861 -1.266494  ]\n",
            " [ 0.989475   -0.02572972  0.2553985  -0.845855  ]\n",
            " [ 0.98203295 -0.33542147  0.57010895 -0.66561127]]\n",
            "K_np=array([[-0.14234572,  1.12553115, -0.91517874, -1.2557506 ],\n",
            "       [ 1.24368024,  0.12450988,  0.19428861, -1.26649397],\n",
            "       [ 0.98947497, -0.02572972,  0.25539853, -0.84585492],\n",
            "       [ 0.98203293, -0.33542146,  0.57010891, -0.66561129]])\n",
            "K is not similar\n",
            "V=[[-1.4943337   0.22304492  0.5137239  -0.76285994]\n",
            " [-0.5250175   0.16229238  0.92345756 -0.8253772 ]\n",
            " [-0.43513     0.07947831  0.9863903  -0.64482915]\n",
            " [-0.07674776 -0.0632465   1.0501893  -0.44635892]]\n",
            "V_np=array([[-1.49433365,  0.22304491,  0.51372392, -0.7628599 ],\n",
            "       [-0.52501754,  0.16229238,  0.9234576 , -0.82537725],\n",
            "       [-0.43512996,  0.0794783 ,  0.98639025, -0.64482916],\n",
            "       [-0.07674777, -0.06324649,  1.05018927, -0.44635892]])\n",
            "V is not similar\n"
          ]
        }
      ],
      "source": [
        "split_dim = int(QKV_b_np.shape[1] / 3)\n",
        "\n",
        "Q_np = QKV_b_np[:, : split_dim]\n",
        "K_np = QKV_b_np[:, split_dim : 2 * split_dim]\n",
        "V_np = QKV_b_np[:, 2 * split_dim :]\n",
        "\n",
        "if (Q.compare(Q_np)):\n",
        "  print(\"Q is similar!\")\n",
        "else:\n",
        "  print(f\"{Q=}\")\n",
        "  print(f\"{Q_np=}\")\n",
        "  print(\"Q is not similar\")\n",
        "\n",
        "if (K.compare(K_np)):\n",
        "  print(\"K is similar!\")\n",
        "else:\n",
        "  print(f\"{K=}\")\n",
        "  print(f\"{K_np=}\")\n",
        "  print(\"K is not similar\")\n",
        "\n",
        "if (V.compare(V_np)):\n",
        "  print(\"V is similar!\")\n",
        "else:\n",
        "  print(f\"{V=}\")\n",
        "  print(f\"{V_np=}\")\n",
        "  print(\"V is not similar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled=[[ 0.41700038  0.01378758 -0.03586942 -0.2379791 ]\n",
            " [ 0.41423714 -0.65813804 -0.55616087 -0.870016  ]\n",
            " [ 0.34651658 -1.003629   -0.81932783 -1.0939575 ]\n",
            " [ 0.3563763  -1.1384946  -0.9263183  -1.1924647 ]]\n",
            "score_scaled_np=array([[ 0.41700038,  0.01378754, -0.03586946, -0.23797911],\n",
            "       [ 0.4142372 , -0.6581379 , -0.55616079, -0.87001593],\n",
            "       [ 0.34651665, -1.00362892, -0.81932781, -1.09395758],\n",
            "       [ 0.35637629, -1.13849449, -0.9263182 , -1.19246465]])\n"
          ]
        }
      ],
      "source": [
        "score_scaled = (Q * K.transpose()) / math.sqrt(Q.num_cols)\n",
        "score_scaled_np = (Q_np @ K_np.T) / math.sqrt(Q.num_cols)\n",
        "\n",
        "print(f\"{score_scaled=}\")\n",
        "print(f\"{score_scaled_np=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_a=[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "Before: test_output=[[0.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]]\n",
            "Returning the cached matrix value!\n",
            "After: test_output=[[0.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]]\n"
          ]
        }
      ],
      "source": [
        "test_a = Matrix(4,4,np.float32,gpu=True)\n",
        "test_a.alloc_on_gpu()\n",
        "test_a.init_incremental()\n",
        "\n",
        "test_output = Matrix(4,1,np.float32,gpu=True)\n",
        "test_output.alloc_on_gpu()\n",
        "test_output.init_incremental()\n",
        "\n",
        "print(f\"{test_a=}\")\n",
        "print(f\"Before: {test_output=}\")\n",
        "\n",
        "matrix_row_wise_add(test_a.a_gpu,\n",
        "        np.int32(test_a.num_rows),\n",
        "        np.int32(test_a.num_cols),\n",
        "        test_output.a_gpu,\n",
        "        block=(test_a.num_cols,test_a.num_rows,1),\n",
        "        shared=test_a.num_elements() * test_a.dtype().nbytes)\n",
        "\n",
        "print(f\"After: {test_output=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled_row_sum=[[ 0.15693945]\n",
            " [-1.6700778 ]\n",
            " [-2.5703979 ]\n",
            " [-2.9009013 ]]\n"
          ]
        }
      ],
      "source": [
        "score_scaled_row_sum = Matrix(score_scaled.num_rows, 1, np.float32, gpu=True)\n",
        "score_scaled_row_sum.alloc_on_gpu()\n",
        "\n",
        "matrix_row_wise_add(score_scaled.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_row_sum.a_gpu,\n",
        "        block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "        shared=score_scaled.num_elements() * score_scaled.dtype().nbytes)\n",
        "\n",
        "print(f\"{score_scaled_row_sum=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 456,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled_row_sum_np=array([ 0.15693935, -1.67007742, -2.57039766, -2.90090105])\n"
          ]
        }
      ],
      "source": [
        "score_scaled_row_sum_np = np.sum(score_scaled_np, axis=1)\n",
        "print(f\"{score_scaled_row_sum_np=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled_row_max=[[0.41700038]\n",
            " [0.41423714]\n",
            " [0.34651658]\n",
            " [0.3563763 ]]\n"
          ]
        }
      ],
      "source": [
        "score_scaled_row_max = Matrix(score_scaled.num_rows, 1, np.float32, gpu=True)\n",
        "score_scaled_row_max.alloc_on_gpu()\n",
        "\n",
        "matrix_row_wise_max(score_scaled.a_gpu,\n",
        "        np.int32(score_scaled.num_rows),\n",
        "        np.int32(score_scaled.num_cols),\n",
        "        score_scaled_row_max.a_gpu,\n",
        "        block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "        shared=score_scaled.num_elements() * score_scaled.dtype().nbytes)\n",
        "\n",
        "print(f\"{score_scaled_row_max=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_scaled_row_max_np=array([0.41700038, 0.4142372 , 0.34651665, 0.35637629])\n"
          ]
        }
      ],
      "source": [
        "score_scaled_row_max_np = np.max(score_scaled_np, axis=1)\n",
        "print(f\"{score_scaled_row_max_np=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out=[[0.35417998 0.23665237 0.22518794 0.18397976]\n",
            " [0.50050443 0.17127    0.18965724 0.1385683 ]\n",
            " [0.5531961  0.14338982 0.17240874 0.13100538]\n",
            " [0.5834099  0.13084576 0.16177322 0.12397116]]\n"
          ]
        }
      ],
      "source": [
        "out = Matrix(score_scaled.num_rows, score_scaled.num_cols, np.float32, gpu=True)\n",
        "out.alloc_on_gpu()\n",
        "out.init_incremental()\n",
        "\n",
        "matrix_bytes = score_scaled.num_elements() * score_scaled.dtype().nbytes\n",
        "shared_mem_bytes = int((3 * matrix_bytes) / 2)\n",
        "\n",
        "fused_softmax(score_scaled.a_gpu,\n",
        "              np.int32(score_scaled.num_rows),\n",
        "              np.int32(score_scaled.num_cols),\n",
        "              out.a_gpu,\n",
        "              block=(score_scaled.num_cols, score_scaled.num_rows, 1),\n",
        "              shared=shared_mem_bytes)\n",
        "\n",
        "print(f\"{out=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score_softmaxed_np=array([[0.34433264, 0.23070931, 0.2349146 , 0.19004345],\n",
            "       [0.48925908, 0.16788517, 0.19893495, 0.1439208 ],\n",
            "       [0.54172503, 0.14080503, 0.18116312, 0.13630682],\n",
            "       [0.57201307, 0.12864469, 0.17019606, 0.12914618]])\n"
          ]
        }
      ],
      "source": [
        "# softmax = exp(score_scaled - score_scaled_row_max) / score_scaled_row_sum_np\n",
        "score_shifted_np = np.exp(score_scaled_np - score_scaled_row_max_np)\n",
        "score_shifted_sum_np = np.sum(score_shifted_np, axis=1, keepdims=True)\n",
        "score_softmaxed_np = score_shifted_np / score_shifted_sum_np\n",
        "print(f\"{score_softmaxed_np=}\")\n",
        "# print(f\"{score_scaled_softmaxed=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'score_scaled_softmaxed' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[461], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(score_scaled_softmaxed.shape)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(V.shape)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[43mscore_scaled_softmaxed\u001b[49m \u001b[38;5;241m*\u001b[39m V\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_output\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'score_scaled_softmaxed' is not defined"
          ]
        }
      ],
      "source": [
        "# print(score_scaled_softmaxed.shape)\n",
        "# print(V.shape)\n",
        "\n",
        "attention_output = score_scaled_softmaxed * V\n",
        "print(f\"{attention_output=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_w_pos=[[ 0.41607213  1.7291827  -0.7984399   1.8122675 ]\n",
            " [ 1.577836    0.44737792  0.29980516  0.32433015]\n",
            " [ 0.8577146  -0.39329472  0.49834803  0.6443237 ]\n",
            " [ 0.5117956  -1.2350745   0.34422183  0.63930935]]\n",
            "Returning the cached matrix value!\n",
            "attention_output=[[-0.7346844   0.13233826 -0.07186561 -0.24650136]\n",
            " [-0.09149098  0.00931656  4.813669   -2.5249176 ]\n",
            " [-0.3978891   0.07214858  2.3947058  -1.3989027 ]\n",
            " [-0.41401434  0.07653806  2.2442029  -1.3293835 ]]\n",
            "[[-0.31861228  1.861521   -0.87030554  1.5657662 ]\n",
            " [ 1.486345    0.45669448  5.1134744  -2.2005875 ]\n",
            " [ 0.4598255  -0.32114613  2.8930538  -0.75457895]\n",
            " [ 0.09778124 -1.1585364   2.5884247  -0.69007415]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"{embeddings_w_pos=}\")\n",
        "print(f\"{attention_output=}\")\n",
        "add = embeddings_w_pos + attention_output\n",
        "print(f\"{add}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNOSc2A+76qSEFerkYh9pBl",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
