{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOSc2A+76qSEFerkYh9pBl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLyoANJiTBe-",
        "outputId": "fb90d9f8-b0a2-48e8-c3b9-7fba169913b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660393 sha256=cd8ba5de6d978049aa51d2eded645b5a8c876e39832588a48c11cb9dd2897649\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.9 pycuda-2025.1 pytools-2025.1.1\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip3 install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.autoinit\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sc4gxOF5TVJP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_code = \"\"\"\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "extern \"C\" __global__ void generate_random_numbers(float* numbers, int n, int seed) {\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  if (idx < n) {\n",
        "    curandState state;\n",
        "    curand_init(seed, idx, 0, &state);\n",
        "    numbers[idx] = curand_uniform(&state);\n",
        "  }\n",
        "}\n",
        "\n",
        "extern \"C\" __global__ void calc_positional_encoding(float* pos_enc, int num_rows, int num_cols, int embedding_dimension) {\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if (row < num_rows && col < num_cols\n",
        "  pos_enc = (current_dim & 1) ? sin(token_idx_in_sentence / (10000 * pow((2 * current_dim) / embedding_dimension) :\n",
        "                                cos(token_idx_in_sentence / (10000 * pow((2 * current_dim) / embedding_dimension)));\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code,\n",
        "                   no_extern_c=True,  # This is important!\n",
        "                   options=[\"-std=c++11\",\n",
        "                           \"-Xcompiler\",\n",
        "                           \"-fPIC\"])"
      ],
      "metadata": {
        "id": "dFsy5cCSbJK-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This is a sentence\"\n",
        "vocab = [\"This\", \"is\", \"a\", \"sentence\"]\n",
        "sentence_toks = [0, 1, 2, 3] # Straight forward\n",
        "word2tok = {\"This\" : 0, \"is\" : 1, \"a\" : 2, \"sentence\" : 3}\n",
        "\n",
        "batch_size =\n",
        "# Create the embedding matrix\n",
        "vocab_size = len(vocab)\n",
        "embedding_dimension = 2 # num of dimensions in each vector in the embedding matrix\n",
        "embedding_num_elements = vocab_size * embedding_dimension\n",
        "embedding_size_bytes = embedding_num_elements * np.float32().nbytes\n",
        "embedding_matrix_gpu = cuda.mem_alloc(embedding_size_bytes)\n",
        "\n",
        "generate_random_numbers = mod.get_function(\"generate_random_numbers\")\n",
        "generate_random_numbers(embedding_matrix_gpu, np.int32(embedding_num_elements), np.int32(0), block=(256, 1, 1), grid=(int(np.ceil(embedding_num_elements / 256)), 1))\n",
        "\n",
        "embedding_matrix_host = np.empty(embedding_num_elements, dtype=np.float32)\n",
        "cuda.memcpy_dtoh(embedding_matrix_host, embedding_matrix_gpu)\n",
        "\n",
        "# print(embedding_matrix_host)\n",
        "\n",
        "# We need to build a method to lookup tokens in the embedding matrix\n",
        "# Use word2tok\n",
        "\n",
        "# Create Positional Encoding\n",
        "# embedding_dimension\n",
        "pos_encodings_batch_size = 512\n",
        "pos_encodings_num_elements = pos_encodings_batch_size * embedding_dimension\n",
        "pos_encodings_size_bytes = pos_encodings_num_elements * np.float32().nbytes\n",
        "pos_encodings_gpu = cuda.mem_alloc(pos_encodings_size_bytes)\n",
        "\n",
        "calc_positional_encoding = mod.get_function(\"calc_positional_encoding\")\n"
      ],
      "metadata": {
        "id": "DNS1PI19Tvas"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUcUeVvLUTuz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}